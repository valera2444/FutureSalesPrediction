{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dac174-80b2-4a38-9771-9ae190679343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9dcc0e-cd2d-4da4-8fe5-73356ee68b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb6d503-8d7d-4314-a81b-13559178de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87186bd9-b9e5-456f-872d-8aaa82a41a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d59db64-170d-48c7-8ba9-158359cce24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f13414-bd09-49bd-aa70-b05a8efd23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../data_cleaned/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a80c07-e7f3-4e53-a0ad-2b7258c4c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data_cleaned/test.csv')\n",
    "test['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6f5ddb-a854-477d-9b14-4c83987b88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([data_train,test ], ignore_index=True).drop('ID', axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9664f55-ca82-484a-a911-b883e8361f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2564</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142680</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142681</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142682</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142683</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142684</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142685 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  \\\n",
       "0        02.01.2013               0       59    22154      999.00   \n",
       "1        03.01.2013               0       25     2552      899.00   \n",
       "2        06.01.2013               0       25     2554     1709.05   \n",
       "3        15.01.2013               0       25     2555     1099.00   \n",
       "4        10.01.2013               0       25     2564      349.00   \n",
       "...             ...             ...      ...      ...         ...   \n",
       "3142680           0              34       45    18454        0.00   \n",
       "3142681           0              34       45    16188        0.00   \n",
       "3142682           0              34       45    15757        0.00   \n",
       "3142683           0              34       45    19648        0.00   \n",
       "3142684           0              34       45      969        0.00   \n",
       "\n",
       "         item_cnt_day  \n",
       "0                 1.0  \n",
       "1                 1.0  \n",
       "2                 1.0  \n",
       "3                 1.0  \n",
       "4                 1.0  \n",
       "...               ...  \n",
       "3142680           0.0  \n",
       "3142681           0.0  \n",
       "3142682           0.0  \n",
       "3142683           0.0  \n",
       "3142684           0.0  \n",
       "\n",
       "[3142685 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64238801-ebdd-4b87-a67f-62cf40287363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_past_ID_s(data_train):\n",
    "    data_train['shop_item'] = [tuple([shop, item]) for shop, item in zip(data_train['shop_id'], data_train['item_id'])]\n",
    "    #34 block contains A LOT more shop_item than others\n",
    "    shop_item_pairs_in_dbn = data_train.groupby('date_block_num')['shop_item'].apply(np.unique)\n",
    "    data_train = data_train.drop(['shop_item'], axis=1)\n",
    "    \n",
    "    shop_item_pairs_WITH_PREV_in_dbn = shop_item_pairs_in_dbn.copy()\n",
    "    \n",
    "    print(np.array(shop_item_pairs_WITH_PREV_in_dbn.index))\n",
    "    arr = np.array(shop_item_pairs_WITH_PREV_in_dbn.index)\n",
    "    \n",
    "    for block in arr[arr>=0]:\n",
    "        if block == 0:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        arr = np.append(shop_item_pairs_WITH_PREV_in_dbn[block -1],\n",
    "                                                            shop_item_pairs_in_dbn[block-1])\n",
    "        \n",
    "        \n",
    "        shop_item_pairs_WITH_PREV_in_dbn[block] = np.unique(np.append(shop_item_pairs_WITH_PREV_in_dbn[block -1],\n",
    "                                                            shop_item_pairs_in_dbn[block-1]))\n",
    "        print(len(shop_item_pairs_WITH_PREV_in_dbn[block]))\n",
    "\n",
    "    return shop_item_pairs_in_dbn, shop_item_pairs_WITH_PREV_in_dbn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554c0468-9296-404e-83ee-22763775ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_past_ID_s_CARTESIAN(data_train):\n",
    "    data_train['shop_item'] = [tuple([shop, item]) for shop, item in zip(data_train['shop_id'], data_train['item_id'])]\n",
    "    #34 block contains A LOT more shop_item than others\n",
    "    shop_item_pairs_in_dbn = data_train.groupby('date_block_num')['shop_item'].apply(np.unique)\n",
    "    data_train = data_train.drop(['shop_item'], axis=1)\n",
    "    \n",
    "    shop_item_pairs_WITH_PREV_in_dbn = np.array([None] * len(shop_item_pairs_in_dbn))\n",
    "    \n",
    "    #print(np.array(shop_item_pairs_WITH_PREV_in_dbn.index))\n",
    "    \n",
    "\n",
    "    cartesians = []\n",
    "    for dbn in shop_item_pairs_in_dbn.index:\n",
    "        val = shop_item_pairs_in_dbn[dbn]\n",
    "\n",
    "        shops = np.unique(list(zip(*val))[0])\n",
    "        items = np.unique(list(zip(*val))[1])\n",
    "    \n",
    "        cartesian_product = np.random.permutation (np.array(np.meshgrid(shops, items)).T.reshape(-1, 2))\n",
    "        #print(cartesian_product)\n",
    "        cartesians.append(cartesian_product)\n",
    "        \n",
    "    \n",
    "    shop_item_pairs_WITH_PREV_in_dbn[0] = cartesians[0]\n",
    "    \n",
    "    for block in shop_item_pairs_in_dbn.index:\n",
    "        if block == 0:\n",
    "            continue\n",
    "        arr = np.append(shop_item_pairs_WITH_PREV_in_dbn[block - 1],\n",
    "                             cartesians[block - 1], axis=0)\n",
    "        \n",
    "        shop_item_pairs_WITH_PREV_in_dbn[block] = np.unique(arr, axis=0)\n",
    "        print(len(shop_item_pairs_WITH_PREV_in_dbn[block]))\n",
    "    return shop_item_pairs_in_dbn, shop_item_pairs_WITH_PREV_in_dbn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6dc1798-6cad-4c98-b648-0807331d129f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364950\n",
      "428871\n",
      "466086\n",
      "494493\n",
      "532909\n",
      "566259\n",
      "587979\n",
      "609623\n",
      "627192\n",
      "664844\n",
      "686985\n",
      "719696\n",
      "730116\n",
      "746129\n",
      "775024\n",
      "799403\n",
      "814628\n",
      "828506\n",
      "851457\n",
      "871899\n",
      "890066\n",
      "928598\n",
      "952398\n",
      "976804\n",
      "987057\n",
      "997953\n",
      "1013772\n",
      "1025692\n",
      "1035736\n",
      "1046582\n",
      "1055558\n",
      "1067461\n",
      "1080188\n",
      "1110590\n"
     ]
    }
   ],
   "source": [
    "shop_item_pairs_in_dbn, shop_item_pairs_WITH_PREV_in_dbn = prepare_past_ID_s_CARTESIAN(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f1f9a1-a1c9-4061-b356-5b536ef28fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.concat([shop_item_pairs_WITH_PREV_in_dbn.map(len),shop_item_pairs_in_dbn.map(len)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b68fee-1c1a-491d-899b-8aa7798e0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75bdcebb-258f-4bb6-8fe7-4cc998ae11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ac9cfe-7563-457e-be30-b28799b2d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_lag_format(data, dbn):\n",
    "    \"\"\"\n",
    "    transform X to lag format\n",
    "    columns with dbn in names become lag_0, dbn-1 - lag_1 etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    lag_cols = defaultdict()\n",
    "    for col in data.columns:\n",
    "        splitted = col.split('$')\n",
    "        if len(splitted) == 1:\n",
    "            continue\n",
    "        \n",
    "        lag_cols[col] = splitted[0] + '_lag;' + str(dbn - int(splitted[1]))\n",
    "\n",
    "    #print(lag_cols)\n",
    "    data = data.rename(columns=dict(lag_cols))\n",
    "    #print(data.columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7621cf0-3ab0-4cb6-aa66-e1d3f4cd817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(data, valid ):\n",
    "    \"\"\"\n",
    "    returns one batch of merged data with required IDs from valid\n",
    "    \"\"\"\n",
    "    #print(data)\n",
    "    valid_shop_item = valid\n",
    "    valid_shop_item = list(zip(*valid_shop_item))\n",
    "    df = pd.DataFrame({'item_id':valid_shop_item[1],'shop_id':valid_shop_item[0]} )\n",
    "    data = df.merge(data, on=['shop_id','item_id'], how='left').fillna(0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e601036-36bd-49a8-9c88-926b1c817062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_val(data, valid ):\n",
    "    \"\"\"\n",
    "    returns one batch of merged data with required IDs from valid\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame({'item_id':valid[:,1],'shop_id':valid[:,0]} )\n",
    "    data = df.merge(data, on=['shop_id','item_id'], how='left').fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9891c579-9b0d-43fc-b3e4-a83b6f1d55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5701d92f-5772-4664-8d54-8d38e33b7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_train_boosting(data, valid, dbn):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    train = prepare_train (data, valid)\n",
    "    lag_cols = []\n",
    "    for col in data.columns:\n",
    "        \n",
    "        splitted = col.split('$')\n",
    "        if len(splitted) == 1:\n",
    "                lag_cols.append(col)\n",
    "                continue\n",
    "        #if 'shop_item_cnt' not in col:\n",
    "        #    continue\n",
    "            \n",
    "        for db in range(0,dbn-1):\n",
    "            \n",
    "            if db == int(splitted[1]):\n",
    "                #print(col)\n",
    "                lag_cols.append(col)\n",
    "\n",
    "    #print(lag_cols)\n",
    "    X = train[lag_cols]\n",
    "    Y = train[f'shop_item_cnt${dbn-1}']\n",
    "    \n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0a5fe-2a8e-4744-a045-da54df2ea451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ba88ce-aa62-4d64-93e2-c0000283582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_validation_boosting(data, valid, dbn):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    test = prepare_val (data, valid)\n",
    "    \n",
    "    lag_cols = []\n",
    "    for col in test.columns:\n",
    "        \n",
    "            \n",
    "        splitted = col.split('$')\n",
    "        if len(splitted) == 1:\n",
    "                lag_cols.append(col)\n",
    "                continue\n",
    "        #if 'shop_item_cnt' not in col:\n",
    "        #    continue\n",
    "        for db in range(1,dbn):\n",
    "            \n",
    "            if db == int(splitted[1]):\n",
    "                #print(db, int(''.join(re.findall(r'\\d+', col))))\n",
    "                lag_cols.append(col)\n",
    "\n",
    "    X = test[lag_cols]\n",
    "    Y = test[f'shop_item_cnt${dbn}']\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7667a652-2001-4d72-b6e2-4f23211b2cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd2033b2-0c53-41b6-be39-812be63a909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_train(merged, batch_size, dbn):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #merged = pd.read_csv('data/merged.csv', chunksize=500000)\n",
    "    #merged = pd.read_csv('data/merged.csv')\n",
    "    train = np.random.permutation (shop_item_pairs_WITH_PREV_in_dbn[dbn])\n",
    "    chunck_num = (len(train)  // batch_size) if batch_size <= len(train) else 1\n",
    "    \n",
    "    for idx in range(chunck_num):#split shop_item_pairs_WITH_PREV_in_dbn into chuncks\n",
    "        #for chunck in merged:#split merged into chuncks\n",
    "        train_ret = prepare_data_train_boosting(merged,train[idx*batch_size:(idx+1)*batch_size], dbn)\n",
    "       \n",
    "        if  train_ret[0].empty:\n",
    "            yield [None, None]\n",
    "        \n",
    "        yield train_ret#, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1671dc4a-f498-4b79-95a6-2832c880114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_val(merged, batch_size, dbn):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #merged = pd.read_csv('data/merged.csv', chunksize=500000) - (DOESNT WORK PROPERLY))))) - use it if merged doesnt fit memory\n",
    "    #merged = pd.read_csv('data/merged.csv')\n",
    "    val = shop_item_pairs_in_dbn[dbn]\n",
    "\n",
    "    shops = np.unique(list(zip(*val))[0])\n",
    "    items = np.unique(list(zip(*val))[1])\n",
    "\n",
    "    cartesian_product = np.random.permutation (np.array(np.meshgrid(shops, items)).T.reshape(-1, 2))\n",
    "    \n",
    "    chunck_num = (len(cartesian_product)  // batch_size) + 1\n",
    "    for idx in range(chunck_num):\n",
    "        #for chunck in merged:\n",
    "        train_ret = prepare_data_validation_boosting(merged,cartesian_product[idx*batch_size:(idx+1)*batch_size], dbn)\n",
    "        #When in batches idx no elements that are in (shop, item) in batch of merged\n",
    "        if  train_ret[0].empty:\n",
    "            \n",
    "            yield [None, None]\n",
    "        #print(len(train_ret))\n",
    "        \n",
    "        yield train_ret#, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850037d1-78af-4240-bad5-38f6d1afa88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_price_change',\n",
       " 'shop_item_price_change',\n",
       " 'ema_6_item_cnt_month_item_id',\n",
       " 'ema_6_item_cnt_month_item_id_shop_id',\n",
       " 'ema_6_item_cnt_month_item_category_id_cat_city',\n",
       " 'ema_6_item_cnt_month_item_category_id_cat_shop_id',\n",
       " 'date_block_num_diff',\n",
       " 'avg_item_priceitem_id_lag_1',\n",
       " 'item_cnt_monthitem_category_id_cat_lag_1',\n",
       " 'item_cnt_month_lag_1']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_base = ['ema_6_item_cnt_month_item_id',\n",
    "         'ema_6_item_cnt_month_item_id_shop_id',\n",
    "         'ema_6_item_cnt_month_item_category_id_cat_city',\n",
    "         'ema_6_item_cnt_month_item_category_id_cat_shop_id',\n",
    "         'date_block_num_diff',\n",
    "        'avg_item_priceitem_id_lag_1',\n",
    "        'item_cnt_monthitem_category_id_cat_lag_1',\n",
    "             'item_cnt_month_lag_1']\n",
    "\n",
    "names_changed = ['item_price_change','shop_item_price_change']\n",
    "names = names_changed + names_base\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98e7fd96-5e34-480e-ae6b-d95d69340de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(X_train, dbn):#WHEN LINEAR MODELS, X_train = append_some_columns(X_train,dbn) - to comment\n",
    "    X_train = append_some_columns(X_train,dbn)\n",
    "    shop_item_cnt_lags= [1,2,3,4,5,6,7,8,9,10,11,12,24]\n",
    "    cols=[]\n",
    "\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        l = col.split(';')\n",
    "        if len(l) == 1:\n",
    "            cols.append(col)\n",
    "            continue\n",
    "\n",
    "        name = l[0]\n",
    "        num = int(l[1])\n",
    "        #if 'change' in name:\n",
    "        #    continue\n",
    "        \n",
    "        #if 'ema' in name:\n",
    "        #    continue\n",
    "            \n",
    "        if 'ema_6_item_cnt_month_item_category_id_cat_city' in name:\n",
    "           if num == 1:\n",
    "                cols.append(col)\n",
    "                continue\n",
    "            \n",
    "       \n",
    "        if 'ema_6_item_cnt_month_item_id_shop_id' in name:\n",
    "            if num == 1:\n",
    "                cols.append(col)\n",
    "                continue\n",
    "            \n",
    "        if 'diff' in name:\n",
    "            if num == 1:\n",
    "                cols.append(col)\n",
    "                continue\n",
    "\n",
    "            continue\n",
    "            \n",
    "        if 'change' in name:\n",
    "\n",
    "            if num <= 3:\n",
    "                cols.append(col)\n",
    "                continue\n",
    "\n",
    "            continue\n",
    "                \n",
    "        if 'ema' in name:\n",
    "            if num <= 1:\n",
    "                cols.append(col)\n",
    "                continue\n",
    "\n",
    "            continue\n",
    "               \n",
    "        if 'price' in name:\n",
    "            if num <= 3:\n",
    "                cols.append(col)\n",
    "                continue\n",
    "\n",
    "            continue\n",
    "        \n",
    "        if 'shop_item_cnt' in name:\n",
    "           # if num <=6 or num == 12:\n",
    "           cols.append(col)\n",
    "            #    continue\n",
    "        \n",
    "    \n",
    "    \n",
    "    return X_train[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "365fc686-e540-4521-a3e3-afb5aad34203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_some_columns(X_train, dbn):\n",
    "    X_train['date_block_num'] = dbn\n",
    "    X_train['month'] = dbn%12\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b7b3985-f7cc-4a16-af3c-15846066cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "031d0aa0-db56-45a7-8853-a80256bc1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b281841f-bdb0-4be9-bd7d-a39f6a2e0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9ba1731-c9fd-42a6-8399-ad09a9c84c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model=xgb.XGBRegressor(tree_method=\"hist\",\n",
    "#                       #early_stopping_rounds=15,\n",
    "#                       enable_categorical=True,\n",
    "#                       #max_depth = 10,\n",
    "#                       max_leaves=512,\n",
    "#                       n_estimators = 100,\n",
    "#                       learning_rate = 0.005\n",
    "#                       )\n",
    "\n",
    "\n",
    "#model =RandomForestRegressor(max_depth = 11, n_estimators = 150,n_jobs=8)\n",
    "model = LGBMRegressor(verbose=-1,n_jobs=8, num_leaves=340, n_estimators = 500,  learning_rate=0.005)\n",
    "#model = Lasso()\n",
    "#model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10fbfbb4-2de1-4c9c-9fcc-071c20870c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lightgbm.sklearn.LGBMRegressor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f76bc-ff0a-4114-8f3e-160174cb3246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96784c6e-0884-4c8a-bd0e-89734a536504",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, merged,batch_size, val_month):\n",
    "    \n",
    "    first=True\n",
    "    rmse = 0\n",
    "    c=0\n",
    "    columns_order=None\n",
    "    \n",
    "    Y_true_l = []\n",
    "    preds_l = []\n",
    "    for X_train,Y_train  in create_batch_train(merged,batch_size, val_month):\n",
    "        \n",
    "        if type(model) in [Lasso,SVC]:\n",
    "            #print(X_train.columns)\n",
    "            X_train.drop('shop_id', inplace=True, axis=1) \n",
    "            X_train.drop('item_category_id', inplace=True, axis=1) \n",
    "            X_train.drop('item_id', inplace=True, axis=1)\n",
    "        else:\n",
    "            #print(list(X_train.columns))\n",
    "        \n",
    "            #X_train = X_train.drop('item_id', axis=1)\n",
    "            X_train['shop_id'] = X_train['shop_id'].astype('category')\n",
    "            X_train['item_category_id'] = X_train['item_category_id'].astype('category')\n",
    "            X_train['city'] = X_train['city'].astype('category')\n",
    "            X_train['super_category'] = X_train['super_category'].astype('category')\n",
    "            \n",
    "            pass\n",
    "           \n",
    "        if X_train is None:\n",
    "            print('None')\n",
    "            continue\n",
    "            \n",
    "        Y_train = np.clip(Y_train,0,20)\n",
    "        \n",
    "        if X_train.empty:\n",
    "            print('None')\n",
    "            continue\n",
    "        \n",
    "        X_train = make_X_lag_format(X_train, val_month-1)\n",
    "        \n",
    "        X_train=select_columns(X_train, val_month-1)\n",
    "        \n",
    "            \n",
    "        columns_order=X_train.columns\n",
    "\n",
    "        if c == 0:\n",
    "            print('train columns')\n",
    "            #print(X_train.columns)\n",
    "        if type(model) in [Lasso,SVC]:\n",
    "            model.fit(X_train, Y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        \n",
    "        elif type(model) == LGBMRegressor:\n",
    "            if first:\n",
    "                model.fit(X_train, Y_train)\n",
    "                first=False\n",
    "            else:\n",
    "                model.fit(X_train, Y_train, init_model=model)\n",
    "            y_train_pred = model.predict(X_train, validate_features=True)\n",
    "\n",
    "        elif type(model) == xgb.XGBRegressor:\n",
    "            if first:\n",
    "                model=model.fit(X_train, Y_train)\n",
    "                first=False\n",
    "            else:\n",
    "                print(model.get_booster())\n",
    "                model=model.fit(X_train, Y_train, xgb_model=model.get_booster())\n",
    "                print('n_estimators:', model.n_estimators)\n",
    "                \n",
    "            y_train_pred = model.predict(X_train)  \n",
    "\n",
    "        elif type(model) == RandomForestRegressor:\n",
    "            model.fit(X_train, Y_train)\n",
    "            y_train_pred = model.predict(X_train)  \n",
    "        \n",
    "        \n",
    "        \n",
    "        Y_true_l.append(Y_train)\n",
    "        preds_l.append(y_train_pred)\n",
    "        \n",
    "        c+=1\n",
    "        \n",
    "    train_rmse = root_mean_squared_error(pd.concat(Y_true_l), np.concat(preds_l))\n",
    "    print('train_rmse, ',train_rmse)\n",
    "           \n",
    "\n",
    "    return model, columns_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dee3eaf3-559a-4b78-bfda-9ef3d573fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model,merged,batch_size, val_month, columns_order):\n",
    "    rmse = 0\n",
    "    c=0\n",
    "    \n",
    "    val_preds = []\n",
    "    Y_true_l = []\n",
    "    preds_l = []\n",
    "    #create_batch_train(merged,batch_size, val_month) - return train set, where Y_val\n",
    "    #is shop_item_cnt_month{val_month}\n",
    "    for X_val, Y_val in create_batch_val(merged,batch_size, val_month):#but then cartesian product used\n",
    "\n",
    "        if type(model) in [sklearn.linear_model._coordinate_descent.Lasso,\n",
    "                          SVC]:\n",
    "            \n",
    "            X_val.drop('shop_id', inplace=True, axis=1) \n",
    "            X_val.drop('item_category_id', inplace=True, axis=1) \n",
    "            X_val.drop('item_id', inplace=True, axis=1) \n",
    "            \n",
    "\n",
    "        else:\n",
    "            \n",
    "            #X_val = X_val.drop('item_id', axis=1)\n",
    "            X_val['shop_id'] = X_val['shop_id'].astype('category')\n",
    "            X_val['item_category_id'] = X_val['item_category_id'].astype('category')\n",
    "            X_val['city'] = X_val['city'].astype('category')\n",
    "            X_val['super_category'] = X_val['super_category'].astype('category')\n",
    "                    \n",
    "            pass\n",
    "            \n",
    "        if X_val is None:\n",
    "            continue\n",
    "            \n",
    "        Y_val = np.clip(Y_val,0,20)\n",
    "        \n",
    "        \n",
    "        X_val = make_X_lag_format(X_val, val_month)\n",
    "        \n",
    "        X_val=select_columns(X_val, val_month)\n",
    "        X_val = X_val[columns_order]\n",
    "\n",
    "        if type(model) in [Lasso,SVC]:\n",
    "            y_val_pred = model.predict(X_val)#lgb - validate features\n",
    "            \n",
    "        elif type(model) ==LGBMRegressor:\n",
    "            y_val_pred = model.predict(X_val, validate_features=True)#lgb - validate features\n",
    "\n",
    "        elif type(model) == xgb.XGBRegressor:\n",
    "            y_val_pred = model.predict(X_val)   \n",
    "\n",
    "        elif type(model) == RandomForestRegressor:\n",
    "            y_val_pred = model.predict(X_val)  \n",
    "\n",
    "        y_val_pred = np.clip(y_val_pred,0,20)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        preds_l.append(y_val_pred)\n",
    "        Y_true_l.append(Y_val)\n",
    "        \n",
    "        c+=1\n",
    "        \n",
    "        val_preds.append(y_val_pred)\n",
    "\n",
    "    \n",
    "    val_rmse = root_mean_squared_error(pd.concat(Y_true_l), np.concat(preds_l))\n",
    "    print('val rmse, ',val_rmse)\n",
    "\n",
    "    return val_preds, val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1561f7b-e24f-44c7-a404-70412fc936b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ML(merged, start_val_month):\n",
    "    \"\"\"\n",
    "    Function for validating model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    val_errors = []\n",
    "    batch_size=100000\n",
    "    val_preds=[]\n",
    "    \n",
    "    \n",
    "    for val_month in range(start_val_month, 34):\n",
    "\n",
    "        \n",
    "        model = LGBMRegressor(verbose=-1,n_jobs=8, num_leaves=456, n_estimators = 500,  learning_rate=0.005)\n",
    "\n",
    "        \n",
    "        print('date_block_num', val_month)\n",
    "        print('month', val_month%12)\n",
    "\n",
    "        model,columns_order = train_model(model, merged,batch_size, val_month)\n",
    "        print('feature importances, ')\n",
    "        print(list(model.feature_names_in_[np.argsort( model.feature_importances_)][::-1]))\n",
    "        \n",
    "        #dump_list = model.get_booster().get_dump()\n",
    "        #num_trees = len(dump_list)\n",
    "        \n",
    "        print('n_estimators:', model.n_estimators_)\n",
    "        val_pred, val_error = validate_model(model,merged,batch_size, val_month,columns_order)\n",
    "        \n",
    "        val_errors.append(val_error)\n",
    "        val_preds.append(val_pred)\n",
    "        \n",
    "\n",
    "    return val_errors, val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83a2aa-cb48-4ab8-bbd5-0b7afe3bb617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0f1941f-4be5-4ff5-acd2-55f10b74540d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_block_num 22\n",
      "month 10\n",
      "train columns\n",
      "train_rmse,  0.4335074696504726\n",
      "feature importances, \n",
      "[np.str_('item_id'), np.str_('ema_6_item_cnt_month_item_category_id_cat_shop_id_lag;1'), np.str_('ema_6_item_cnt_month_item_category_id_cat_city_lag;1'), np.str_('ema_6_item_cnt_month_item_id_lag;1'), np.str_('avg_item_priceitem_id_lag_1_lag;1'), np.str_('shop_id'), np.str_('date_block_num_diff_lag;1'), np.str_('avg_item_priceitem_id_lag_1_lag;3'), np.str_('shop_item_cnt_lag;1'), np.str_('item_category_id'), np.str_('item_price_change_lag;1'), np.str_('avg_item_priceitem_id_lag_1_lag;2'), np.str_('item_price_change_lag;2'), np.str_('item_price_change_lag;3'), np.str_('ema_6_item_cnt_month_item_id_shop_id_lag;1'), np.str_('shop_item_cnt_lag;2'), np.str_('shop_item_cnt_lag;3'), np.str_('shop_item_cnt_lag;12'), np.str_('shop_item_cnt_lag;4'), np.str_('shop_item_cnt_lag;10'), np.str_('shop_item_cnt_lag;5'), np.str_('shop_item_cnt_lag;6'), np.str_('shop_item_cnt_lag;7'), np.str_('shop_item_cnt_lag;21'), np.str_('shop_item_cnt_lag;9'), np.str_('shop_item_cnt_lag;8'), np.str_('city'), np.str_('shop_item_cnt_lag;11'), np.str_('shop_item_cnt_lag;19'), np.str_('shop_item_cnt_lag;14'), np.str_('shop_item_cnt_lag;20'), np.str_('shop_item_cnt_lag;13'), np.str_('shop_item_cnt_lag;15'), np.str_('shop_item_cnt_lag;17'), np.str_('shop_item_cnt_lag;16'), np.str_('shop_item_cnt_lag;18'), np.str_('super_category'), np.str_('month'), np.str_('date_block_num')]\n",
      "n_estimators: 4500\n",
      "val rmse,  1.1045163676916414\n",
      "date_block_num 23\n",
      "month 11\n",
      "train columns\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start_val_month\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m\n\u001b[0;32m----> 3\u001b[0m val_errors, val_preds \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_val_month\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Some feature names contains 2 word 'lag'. First word lag comes from column names in ./data.csv\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m, in \u001b[0;36mvalidate_ML\u001b[0;34m(merged, model, start_val_month)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_block_num\u001b[39m\u001b[38;5;124m'\u001b[39m, val_month)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, val_month\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m model,columns_order \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_month\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature importances, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mfeature_names_in_[np\u001b[38;5;241m.\u001b[39margsort( model\u001b[38;5;241m.\u001b[39mfeature_importances_)][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[32], line 58\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, merged, batch_size, val_month)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, init_model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m---> 58\u001b[0m     y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(model) \u001b[38;5;241m==\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first:\n",
      "File \u001b[0;32m~/python_envs/predict_future_sales/lib/python3.12/site-packages/lightgbm/sklearn.py:1036\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m _choose_param_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m   1034\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_n_jobs(predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Booster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_envs/predict_future_sales/lib/python3.12/site-packages/lightgbm/basic.py:4748\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   4746\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4747\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 4748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_envs/predict_future_sales/lib/python3.12/site-packages/lightgbm/basic.py:1185\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_csc(\n\u001b[1;32m   1179\u001b[0m         csc\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1180\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[1;32m   1181\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[1;32m   1182\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type,\n\u001b[1;32m   1183\u001b[0m     )\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 1185\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pred_for_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[1;32m   1192\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_pyarrow_table(\n\u001b[1;32m   1193\u001b[0m         table\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1194\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[1;32m   1195\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[1;32m   1196\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type,\n\u001b[1;32m   1197\u001b[0m     )\n",
      "File \u001b[0;32m~/python_envs/predict_future_sales/lib/python3.12/site-packages/lightgbm/basic.py:1344\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, nrow\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_predict_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_envs/predict_future_sales/lib/python3.12/site-packages/lightgbm/basic.py:1291\u001b[0m, in \u001b[0;36m_InnerPredictor.__inner_predict_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length of pre-allocated predict array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1289\u001b[0m out_num_preds \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int64(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1290\u001b[0m _safe_call(\n\u001b[0;32m-> 1291\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterPredictForMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_C_API_IS_ROW_MAJOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_parameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_num_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_double\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m )\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_preds \u001b[38;5;241m!=\u001b[39m out_num_preds\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length for predict results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_val_month=22\n",
    "\n",
    "val_errors, val_preds = validate_ML(merged,start_val_month)\n",
    "#Some feature names contains 2 word 'lag'. First word lag comes from column names in ./data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284957bf-14ce-479f-9deb-fc1743314820",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1.1131333259192753, \n",
    "1.280538425526827,\n",
    "1.1267832346268418,\n",
    "0.8577197073585947,\n",
    "0.852271386468949, \n",
    "0.955775029714284,\n",
    "0.892993924504934,\n",
    "0.8300112585408684,\n",
    "0.7460129792132149,\n",
    "0.8224050978044093,\n",
    "0.979549517863459,\n",
    "1.0014096241176884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abc675-bfa4-41bf-a9c3-28bfce6c6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092d6d9-e202-4b0e-af60-d56de75fc05d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(val_errors).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8d4781d-35ad-44dc-81e8-b6f6f0648ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(model,merged,batch_size, columns_order):\n",
    "    val_month = 34\n",
    "    test = pd.read_csv('../data_cleaned/test.csv')\n",
    "    \n",
    "    data_test = test\n",
    "    PREDICTION = pd.DataFrame(columns=['shop_id','item_id','item_cnt_month'])\n",
    "    Y_true_l=[]\n",
    "    for X_val, Y_val in create_batch_val(merged,batch_size, val_month):\n",
    "        if type(model) in [sklearn.linear_model._coordinate_descent.Lasso,\n",
    "                          SVC]:\n",
    "            \n",
    "            X_val.drop('shop_id', inplace=True, axis=1) \n",
    "            X_val.drop('item_category_id', inplace=True, axis=1) \n",
    "            X_val.drop('item_id', inplace=True, axis=1) \n",
    "            \n",
    "\n",
    "        else:\n",
    "            \n",
    "            #X_val = X_val.drop('item_id', axis=1)\n",
    "            X_val['shop_id'] = X_val['shop_id'].astype('category')\n",
    "            X_val['item_category_id'] = X_val['item_category_id'].astype('category')\n",
    "            X_val['city'] = X_val['city'].astype('category')\n",
    "            X_val['super_category'] = X_val['super_category'].astype('category')\n",
    "                    \n",
    "            pass\n",
    "\n",
    "        \n",
    "        if X_val is None:\n",
    "            continue\n",
    "            \n",
    "        Y_val = np.clip(Y_val,0,20)\n",
    "        \n",
    "        if X_val.empty:\n",
    "            print('None')\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        X_val = make_X_lag_format(X_val, val_month)\n",
    "        X_val=select_columns(X_val, val_month)\n",
    "        X_val = X_val[columns_order]\n",
    "\n",
    "        \n",
    "        y_val_pred=model.predict(X_val)\n",
    "        y_val_pred = np.clip(y_val_pred,0,20)#lgb - validate features\n",
    "        Y_true_l.append(Y_val)\n",
    "        \n",
    "        \n",
    "        app = pd.DataFrame({'item_id':X_val.item_id,'shop_id': X_val.shop_id, 'item_cnt_month':y_val_pred})\n",
    "        PREDICTION = pd.concat([PREDICTION, app],ignore_index=True)\n",
    "\n",
    "    #val_rmse = root_mean_squared_error(PREDICTION['item_cnt_month'], np.concat(Y_true_l))\n",
    "    #print('val rmse, ',val_rmse)\n",
    "    \n",
    "    data_test = data_test.merge(PREDICTION,on=['shop_id','item_id'])[['ID','item_cnt_month']]\n",
    "    return data_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9c0f007-65ae-41d0-910d-a9a17b9f3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_pipeline(merged):\n",
    "    val_errors = []\n",
    "    batch_size=100000\n",
    "    val_errors=[]\n",
    "\n",
    "    model = LGBMRegressor(verbose=-1,n_jobs=8, num_leaves=512, n_estimators = 1000,  learning_rate=0.003)\n",
    "    #model =RandomForestRegressor(max_depth = 11, n_estimators = 150,n_jobs=8)\n",
    "    model,columns_order = train_model(model, merged,batch_size, 34)\n",
    "    \n",
    "    print('Feature importnaces in lgb:')\n",
    "    \n",
    "    print(model.feature_names_in_[np.argsort(model.feature_importances_)][::-1])\n",
    "    #print('n_estimators:', model.n_estimators_)\n",
    "    \n",
    "    data_test = create_submission(model,merged,batch_size,columns_order)\n",
    "\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34ccfaf1-8c82-4383-8195-c6f991a26269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train columns\n",
      "train_rmse,  0.3129824042781292\n",
      "Feature importnaces in lgb:\n",
      "['item_id' 'ema_6_item_cnt_month_item_category_id_cat_shop_id_lag;1'\n",
      " 'ema_6_item_cnt_month_item_category_id_cat_city_lag;1'\n",
      " 'ema_6_item_cnt_month_item_id_lag;1' 'avg_item_priceitem_id_lag_1_lag;1'\n",
      " 'shop_id' 'date_block_num_diff_lag;1' 'avg_item_priceitem_id_lag_1_lag;3'\n",
      " 'avg_item_priceitem_id_lag_1_lag;2' 'item_category_id'\n",
      " 'item_price_change_lag;1' 'item_price_change_lag;2'\n",
      " 'item_price_change_lag;3' 'shop_item_cnt_lag;1'\n",
      " 'ema_6_item_cnt_month_item_id_shop_id_lag;1' 'shop_item_cnt_lag;2'\n",
      " 'shop_item_cnt_lag;3' 'shop_item_cnt_lag;12' 'shop_item_cnt_lag;10'\n",
      " 'shop_item_cnt_lag;4' 'shop_item_cnt_lag;5' 'city' 'shop_item_cnt_lag;7'\n",
      " 'shop_item_cnt_lag;8' 'shop_item_cnt_lag;6' 'shop_item_cnt_lag;9'\n",
      " 'shop_item_cnt_lag;11' 'shop_item_cnt_lag;17' 'shop_item_cnt_lag;24'\n",
      " 'shop_item_cnt_lag;14' 'shop_item_cnt_lag;13' 'shop_item_cnt_lag;16'\n",
      " 'shop_item_cnt_lag;33' 'shop_item_cnt_lag;18' 'shop_item_cnt_lag;15'\n",
      " 'shop_item_cnt_lag;22' 'shop_item_cnt_lag;31' 'shop_item_cnt_lag;19'\n",
      " 'shop_item_cnt_lag;21' 'shop_item_cnt_lag;32' 'shop_item_cnt_lag;30'\n",
      " 'shop_item_cnt_lag;23' 'shop_item_cnt_lag;28' 'shop_item_cnt_lag;26'\n",
      " 'shop_item_cnt_lag;20' 'shop_item_cnt_lag;27' 'shop_item_cnt_lag;29'\n",
      " 'shop_item_cnt_lag;25' 'super_category' 'month' 'date_block_num']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5517/1517395846.py:49: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  PREDICTION = pd.concat([PREDICTION, app],ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "submission = create_submission_pipeline(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9b4fe1a-e885-4c5b-9d4f-4f378356983f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214200.000000</td>\n",
       "      <td>214200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>107099.500000</td>\n",
       "      <td>0.293744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61834.358168</td>\n",
       "      <td>0.803725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53549.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107099.500000</td>\n",
       "      <td>0.079759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>160649.250000</td>\n",
       "      <td>0.283214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>214199.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  item_cnt_month\n",
       "count  214200.000000   214200.000000\n",
       "mean   107099.500000        0.293744\n",
       "std     61834.358168        0.803725\n",
       "min         0.000000        0.000000\n",
       "25%     53549.750000        0.000000\n",
       "50%    107099.500000        0.079759\n",
       "75%    160649.250000        0.283214\n",
       "max    214199.000000       20.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "994efbb0-d233-4959-a865-a33cfed99062",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c769015-a9d8-4870-9774-fb02cfb77241",
   "metadata": {},
   "outputs": [],
   "source": [
    "result:\n",
    "LGBM default:\n",
    "???\n",
    "\n",
    "Lasso\n",
    "validation - 1.122829\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f9d10-381e-4974-9c33-70a0500b0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02887a0-995e-4546-9b6e-34b64f2ca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF on :\n",
    "batch_size=100000???\n",
    "['shop_item_cnt_lag;1',\n",
    " 'item_id', \n",
    " 'ema_6_item_cnt_month_item_category_id_cat_shop_id_lag;1',\n",
    " 'shop_item_cnt_lag;2', \n",
    " 'item_category_id', \n",
    " 'shop_item_cnt_lag;3', \n",
    " 'avg_item_priceitem_id_lag_1_lag;1',\n",
    " 'ema_6_item_cnt_month_item_id_lag;1',\n",
    " 'shop_id', \n",
    " 'date_block_num_diff_lag;1',\n",
    " 'item_price_change_lag;1',\n",
    " 'shop_item_cnt_lag;12',\n",
    " 'avg_item_priceitem_id_lag_1_lag;3', \n",
    " 'city', \n",
    " 'avg_item_priceitem_id_lag_1_lag;2', \n",
    " 'super_category',\n",
    " 'shop_item_cnt_lag;6', \n",
    " 'shop_item_cnt_lag;4', \n",
    " 'item_price_change_lag;2', \n",
    " 'shop_item_cnt_lag;5', \n",
    " 'item_price_change_lag;3', \n",
    " 'month', \n",
    " 'date_block_num']\n",
    "\n",
    "validation - [np.float64(1.1030454661151439),\n",
    " np.float64(1.2808061846792664),\n",
    " np.float64(1.0932161531758702),\n",
    " np.float64(0.8539095663659091),\n",
    " np.float64(0.8556563562276699),\n",
    " np.float64(0.9702615886206524),\n",
    " np.float64(0.9432473239256615),\n",
    " np.float64(0.8404985919353657),\n",
    " np.float64(0.7832955927106592),\n",
    " np.float64(0.8417092000723038),\n",
    " np.float64(0.9909527270877753),\n",
    " np.float64(0.9851377342980254)]\n",
    "mean - np.float64(0.9618113737678584)\n",
    "test - 1.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5080774-aabb-4684-b933-de5c2ffac36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF on :\n",
    "batch_size=100000???\n",
    "['shop_item_cnt_lag;1', \n",
    " 'item_id', \n",
    " 'item_category_id',\n",
    " 'shop_item_cnt_lag;2', \n",
    " 'shop_item_cnt_lag;3', \n",
    " 'shop_id',\n",
    " 'super_category', \n",
    " 'city', \n",
    " 'shop_item_cnt_lag;4', \n",
    " 'shop_item_cnt_lag;9', \n",
    " 'shop_item_cnt_lag;5', \n",
    " 'shop_item_cnt_lag;21', \n",
    " 'shop_item_cnt_lag;6', \n",
    " 'shop_item_cnt_lag;8',\n",
    " 'shop_item_cnt_lag;7',\n",
    " 'shop_item_cnt_lag;10', \n",
    " 'shop_item_cnt_lag;14', \n",
    " 'shop_item_cnt_lag;17', \n",
    " 'shop_item_cnt_lag;12',\n",
    " 'shop_item_cnt_lag;16', \n",
    " 'shop_item_cnt_lag;11',\n",
    " 'shop_item_cnt_lag;19', \n",
    " 'shop_item_cnt_lag;13', \n",
    " 'shop_item_cnt_lag;31',\n",
    " 'shop_item_cnt_lag;22', \n",
    " 'shop_item_cnt_lag;23', \n",
    " 'shop_item_cnt_lag;15',\n",
    " 'shop_item_cnt_lag;28', \n",
    " 'shop_item_cnt_lag;18', \n",
    " 'shop_item_cnt_lag;20', \n",
    " 'shop_item_cnt_lag;30',\n",
    " 'shop_item_cnt_lag;24', \n",
    " 'shop_item_cnt_lag;27', \n",
    " 'shop_item_cnt_lag;26', \n",
    " 'shop_item_cnt_lag;29',\n",
    " 'shop_item_cnt_lag;25', \n",
    " 'month',\n",
    " 'date_block_num']\n",
    "\n",
    "\n",
    "validation - [np.float64(1.1261279577971253),\n",
    " np.float64(1.3063675989401422),\n",
    " np.float64(1.107639823687741),\n",
    " np.float64(0.8568042503316228),\n",
    " np.float64(0.8558897249837448),\n",
    " np.float64(1.0032960741790946),\n",
    " np.float64(0.9291427800382513),\n",
    " np.float64(0.8312809789838309),\n",
    " np.float64(0.7627208542403842),\n",
    " np.float64(0.8455873646630931),\n",
    " np.float64(0.9902778716165955),\n",
    " np.float64(0.9974386033703456)]\n",
    "mean - np.float64(0.9677144902359976)\n",
    "\n",
    "test - 1.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa44bbb-7f4f-4826-a145-730fa370b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting(LGBMRegressor(verbose=-1,n_jobs=8, num_leaves=512, n_estimators = 150,  learning_rate=0.005))on:\n",
    "btch_size = 100000\n",
    "\n",
    "[1.1131333259192753, \n",
    "1.280538425526827,\n",
    "1.1267832346268418,\n",
    "0.8577197073585947,\n",
    "0.852271386468949, \n",
    "0.955775029714284,\n",
    "0.892993924504934,\n",
    "0.8300112585408684,\n",
    "0.7460129792132149,\n",
    "0.8224050978044093,\n",
    "0.979549517863459,\n",
    "1.0014096241176884]\n",
    "mean - 0.9548836259716121\n",
    "test - 1.03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
